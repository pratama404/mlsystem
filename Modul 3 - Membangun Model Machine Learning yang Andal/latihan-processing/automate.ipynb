{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from joblib import dump\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_data(data, target_column, save_path, file_path):\n",
    "    # Menentukan fitur numerik dan kategoris\n",
    "    numeric_features = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "    column_names = data.columns\n",
    "    # Mendapatkan nama kolom tanpa kolom target\n",
    "    column_names = data.columns.drop(target_column)\n",
    "\n",
    "    # Membuat DataFrame kosong dengan nama kolom\n",
    "    df_header = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    # Menyimpan nama kolom sebagai header tanpa data\n",
    "    df_header.to_csv(file_path, index=False)\n",
    "    print(f\"Nama kolom berhasil disimpan ke: {file_path}\")\n",
    "\n",
    "    # Pastikan target_column tidak ada di numeric_features atau categorical_features\n",
    "    if target_column in numeric_features:\n",
    "        numeric_features.remove(target_column)\n",
    "    if target_column in categorical_features:\n",
    "        categorical_features.remove(target_column)\n",
    "\n",
    "    # Pipeline untuk fitur numerik\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Pipeline untuk fitur kategoris\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Column Transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Memisahkan target\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "\n",
    "    # Membagi data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Fitting dan transformasi data pada training set\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    # Transformasi data pada testing set\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "    # Simpan pipeline\n",
    "    dump(preprocessor, save_path)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "# Memuat dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nama kolom berhasil disimpan ke: data.csv\n"
     ]
    }
   ],
   "source": [
    "# Contoh Penggunaan\n",
    "X_train, X_test, y_train, y_test = preprocess_data(data, 'target', 'preprocessor_pipeline.joblib', 'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "def inference(new_data, load_path):\n",
    "    # Memuat pipeline preprocessing\n",
    "    preprocessor = load(load_path)\n",
    "    print(f\"Pipeline preprocessing dimuat dari: {load_path}\")\n",
    "\n",
    "    # Transformasi data baru\n",
    "    transformed_data = preprocessor.transform(new_data)\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_data(transformed_data, load_path, new_data_columns):\n",
    "    preprocessor = load(load_path)\n",
    "    # Membalik transformasi hanya untuk fitur numerik\n",
    "    numeric_transformer = preprocessor.named_transformers_['num']['scaler']\n",
    "    numeric_columns = new_data_columns[:len(numeric_transformer.mean_)]  # Asumsi fitur numerik ada di awal\n",
    "    transformed_numeric_data = transformed_data[:, :len(numeric_columns)]\n",
    "\n",
    "    # Inverse transform untuk data numerik\n",
    "    original_numeric_data = numeric_transformer.inverse_transform(transformed_numeric_data)\n",
    "\n",
    "    # Gabungkan kembali data numerik dengan data kategoris (jika ada)\n",
    "    inversed_data = pd.DataFrame(original_numeric_data, columns=numeric_columns)\n",
    "    return inversed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline preprocessing dimuat dari: preprocessor_pipeline.joblib\n",
      "Data setelah preprocessing (training):\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "\n",
      "Data baru setelah transformasi:\n",
      "[[-0.89573553  1.17645543 -1.44207638 -1.40568508]]\n",
      "\n",
      "Data setelah inverse transform:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Jalankan preprocessing\n",
    "pipeline_path = 'preprocessor_pipeline.joblib'\n",
    "col = pd.read_csv('data.csv')\n",
    "# Daftar data\n",
    "new_data = [5.1, 3.5, 1.4, 0.2]\n",
    "\n",
    "# Mengubah menjadi numpy.ndarray\n",
    "new_data = np.array(new_data)\n",
    "\n",
    "new_data = pd.DataFrame([new_data], columns=col.columns)\n",
    "# Lakukan inference\n",
    "transformed_data = inference(new_data, pipeline_path)\n",
    "\n",
    "# Inverse transform data\n",
    "inversed_data = inverse_transform_data(transformed_data, pipeline_path, new_data.columns)\n",
    "\n",
    "# Output hasil preprocessing dan inference\n",
    "print(\"Data setelah preprocessing (training):\")\n",
    "print(new_data)\n",
    "print(\"\\nData baru setelah transformasi:\")\n",
    "print(transformed_data)\n",
    "print(\"\\nData setelah inverse transform:\")\n",
    "print(inversed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsystem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
